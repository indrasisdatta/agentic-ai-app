{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "import operator \n",
    "from typing_extensions import Literal \n",
    "from pydantic import BaseModel, Field \n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_groq import ChatGroq \n",
    "\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181987ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for structured output \n",
    "class Section(BaseModel):\n",
    "    name: str = Field(description=\"Name of this section of the report\")\n",
    "    description: str = Field(description=\"Brief overview of the main topics and concepts of this section\")\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(description=\"Sections of the report\")\n",
    "\n",
    "# Assign the LLM with a schema for structured output\n",
    "planner = llm.with_structured_output(Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send \n",
    "\n",
    "# Graph state \n",
    "class State(TypedDict):\n",
    "    topic: str  # Report topic \n",
    "    sections: list[Section]  # List of report sections \n",
    "    completed_sections: Annotated[\n",
    "        list, operator.add \n",
    "    ] # All workers write to this key in parallel\n",
    "    final_report: str\n",
    "\n",
    "# Worker state \n",
    "class WorkerState(TypedDict):\n",
    "    section: Section \n",
    "    completed_sections: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator(state: State):\n",
    "    \"\"\"Orchestrator that generates a plan for the report\"\"\"\n",
    "\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Generate a plan for the report\"),\n",
    "            HumanMessage(content=f\"Here is the report topic {state[\"topic\"]}\")\n",
    "        ]\n",
    "    )\n",
    "    print(\"Report sections: \", report_sections)\n",
    "\n",
    "    return {\"sections\": report_sections.sections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd432125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state: WorkerState):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Write a report section following the name and description. Don't include any introduction for each section.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"Here is the section name: {state[\"section\"].name} and description: {state[\"section\"].description}\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    # Write the updated section to completed sections\n",
    "    return {\"completed_sections\": [section.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59311612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional edge function to create llm_call workers that each write a section of the report\n",
    "def assign_workers(state: State):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "\n",
    "    # Section writing in parallel using Send API \n",
    "    return [\n",
    "        Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "    completed_report_sections = \"\\n\\n----\\n\\n\".join(completed_sections)\n",
    "    return {\"final_report\": completed_report_sections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60cf247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build workflow \n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes \n",
    "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
    "orchestrator_worker_builder.add_node(\"llm_call\", llm_call)\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "orchestrator_worker_builder.add_edge(START, \"orchestrator\")\n",
    "orchestrator_worker_builder.add_conditional_edges(\n",
    "    \"orchestrator\", assign_workers, [\"llm_call\"]\n",
    ")\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\")\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the workflow \n",
    "orchestrator_worker = orchestrator_worker_builder.compile()\n",
    "\n",
    "display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "result = orchestrator_worker.invoke({\"topic\": \"Create a report on Agentic AI RAG\"})\n",
    "Markdown(result[\"final_report\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
