{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4bd502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict \n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END \n",
    "\n",
    "# Reducers \n",
    "from typing import Annotated \n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10e40dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class State(TypedDict):\n",
    "#     messages: Annotated[list, add_messages]\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44998c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "207fb25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, Indrasis! üëã How can I assist you today?', additional_kwargs={'reasoning_content': 'The user just says \"Hello, I am Indrasis\". Likely greeting. We should respond politely, maybe ask how we can help.'}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 78, 'total_tokens': 132, 'completion_time': 0.057451017, 'prompt_time': 0.004356328, 'queue_time': 0.051007047, 'total_time': 0.061807345}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6ac59f98-9fc4-44c1-a92f-2b7b960b4b92-0', usage_metadata={'input_tokens': 78, 'output_tokens': 54, 'total_tokens': 132})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq \n",
    "\n",
    "llm_groq = ChatGroq(model=\"openai/gpt-oss-20b\")\n",
    "llm_groq.invoke(\"Hello, I am Indrasis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9574a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def superbot(state: State):\n",
    "    return {\"messages\": llm_groq.invoke(state[\"messages\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76cb9e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"Superbot\", superbot)\n",
    "\n",
    "graph.add_edge(START, \"Superbot\")\n",
    "graph.add_edge(\"Superbot\", END)\n",
    "\n",
    "graph_builder = graph.compile()\n",
    "\n",
    "from IPython.display import Image, display \n",
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc4b978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Hi, I'm learning Agentic AI\", additional_kwargs={}, response_metadata={}, id='fc07c650-af56-49ff-98c5-95bd20eb4eda'),\n",
       "  AIMessage(content='Hello! üëã  \\nIt‚Äôs great that you‚Äôre diving into Agentic AI.  ‚ÄúAgentic‚Äù usually means *autonomous agents that can perceive, reason, and act in a world to achieve goals*‚Äîthe kind of systems that drive self‚Äëdriving cars, personal assistants, or even multi‚Äëagent simulations.\\n\\nBelow is a quick ‚Äústarter kit‚Äù that covers the big ideas, key resources, and a few practical next steps.  Feel free to let me know which parts you‚Äôd like to explore deeper (e.g., theory, coding, ethics, or a specific domain like robotics or LLM‚Äëbased agents).\\n\\n---\\n\\n## 1. Core Concepts\\n\\n| Component | What it is | Typical Tech |\\n|-----------|------------|--------------|\\n| **Perception** | How the agent senses its environment (sensors, vision, language) | CNNs, transformers, LIDAR, NLP models |\\n| **World Model** | Internal representation of the environment | Graphs, latent dynamics models, memory networks |\\n| **Planning / Decision‚ÄëMaking** | Choosing actions to achieve goals | Classical planners, MDPs, RL policies, symbolic planners |\\n| **Learning** | Improving performance over time | Supervised learning, Reinforcement Learning (RL), RL‚ÄëHF |\\n| **Interaction** | Acting in the world / communicating with users | Actuators, APIs, dialogue systems |\\n| **Self‚ÄëReflection / Meta‚ÄëLearning** | Agents that critique or adapt their own policies | Self‚Äëplay, curriculum learning, chain‚Äëof‚Äëthought prompting |\\n\\n---\\n\\n## 2. Quick Learning Path\\n\\n| Stage | What to Study | Suggested Resources |\\n|-------|---------------|---------------------|\\n| **Foundations** | Classical AI & RL fundamentals | *Artificial Intelligence: A Modern Approach* (Russell & Norvig) <br> *Reinforcement Learning: An Introduction* (Sutton & Barto) |\\n| **Deep RL & Planning** | Policy gradients, Q‚Äëlearning, model‚Äëbased RL | DeepMind‚Äôs RL lectures <br> OpenAI Spinning Up |\\n| **Large‚ÄëScale Language Agents** | LLMs, chain‚Äëof‚Äëthought, self‚Äëreflection | OpenAI GPT‚Äë4 docs, ‚ÄúAgentic‚Äù papers (e.g., ‚ÄúReAct: Synergizing Reasoning and Acting in Language Models‚Äù) |\\n| **Multi‚ÄëAgent Systems** | Coordination, game theory, emergent behavior | *Multi‚ÄëAgent Reinforcement Learning* (Sutton et\\u202fal.) <br> DeepMind ‚ÄúMulti‚ÄëAgent Learning‚Äù tutorials |\\n| **Robotics / Physical Agents** | Sim2Real, motion planning, control | Robot Operating System (ROS) tutorials <br> OpenAI Gym‚ÄëRobotics, PyBullet |\\n| **Ethics & Safety** | Alignment, interpretability, fairness | *Alignment: The Machine Learning Problem* (Yudkowsky) <br> OpenAI Safety Papers |\\n\\n---\\n\\n## 3. Hands‚ÄëOn Playbooks\\n\\n| Focus | What to Try | Starter Code / Libraries |\\n|-------|-------------|--------------------------|\\n| **LLM‚ÄëBased Agent** | Build a simple ‚Äúquestion‚Äëanswer‚Äù agent that can browse the web | LangChain, LlamaIndex, OpenAI API |\\n| **RL Agent** | Train a cart‚Äëpole or MountainCar agent | OpenAI Gym + Stable Baselines3 |\\n| **Multi‚ÄëAgent** | Two agents playing a simple game (e.g., soccer) | PettingZoo, RLlib |\\n| **Robotics** | Simulate a robotic arm picking objects | PyBullet, MuJoCo, OpenAI Gym‚ÄëRobotics |\\n| **Hybrid** | Combine RL with LLM prompts (e.g., a ‚Äúplanning‚Äù LLM + ‚Äúcontrol‚Äù RL policy) | ReAct framework, RLHF |\\n\\n---\\n\\n## 4. Key Papers & Articles\\n\\n| Topic | Paper / Link |\\n|-------|--------------|\\n| **Agentic LLMs** | ‚ÄúReAct: Synergizing Reasoning and Acting in Language Models‚Äù (2022) |\\n| **Self‚ÄëReflection** | ‚ÄúSelf‚ÄëCritique: A Language Model for Self‚ÄëImprovement‚Äù (2023) |\\n| **Multi‚ÄëAgent RL** | ‚ÄúMulti‚ÄëAgent Reinforcement Learning: A Survey‚Äù (2020) |\\n| **Robotics RL** | ‚ÄúSim2Real Transfer for Robot Manipulation‚Äù (2021) |\\n| **Safety** | ‚ÄúConcrete Problems in AI Safety‚Äù (2016) ‚Äì OpenAI |\\n\\n---\\n\\n## 5. Communities & Tools\\n\\n| Resource | Why it matters |\\n|----------|----------------|\\n| **GitHub Repos** | `langchain`, `haystack`, `rllib`, `stable-baselines3`, `pettingzoo` |\\n| **Forums** | r/MachineLearning, r/robotics, r/LanguageTechnology |\\n| **Conferences** | NeurIPS, ICML, ICLR, ICRA (robotics), ACL (NLP) |\\n| **Courses** | Coursera ‚ÄúReinforcement Learning‚Äù (University of Alberta) <br> Fast.ai ‚ÄúPractical Deep Learning for Coders‚Äù <br> MIT OpenCourseWare ‚ÄúArtificial Intelligence‚Äù |\\n\\n---\\n\\n## 6. Next Steps (Pick One)\\n\\n1. **Build a simple chatbot agent** that can plan a day‚Äëto‚Äëday schedule using LangChain + GPT‚Äë4.  \\n2. **Train a RL agent** on a classic control task and then extend it to a multi‚Äëagent setting.  \\n3. **Simulate a robotic pick‚Äëand‚Äëplace** task in PyBullet, then try sim‚Äëto‚Äëreal transfer.  \\n4. **Write a short essay** on the ethical implications of autonomous agents in healthcare.\\n\\n---\\n\\n### Quick Code Snippet: LLM Agent with LangChain\\n\\n```python\\nfrom langchain import OpenAI, LLMChain\\nfrom langchain.agents import AgentExecutor, ZeroShotAgent\\n\\nllm = OpenAI(temperature=0.7, model=\"gpt-4\")\\n\\n# Prompt template for a simple planning agent\\nprompt = \"\"\"\\nYou are an autonomous assistant. Given the user‚Äôs goal, produce a step‚Äëby‚Äëstep plan.\\nGoal: {goal}\\nPlan:\\n\"\"\"\\n\\nagent = ZeroShotAgent(llm=llm, prefix=prompt)\\nexecutor = AgentExecutor.from_agent_and_tools(agent, tools=[])\\n\\nresult = executor.run({\"goal\": \"Plan a healthy dinner for 4 people\"})\\nprint(result)\\n```\\n\\n---\\n\\n## 7. Questions for You\\n\\n- Are you more interested in **theoretical foundations** or **hands‚Äëon coding**?  \\n- Do you have a particular domain in mind (e.g., **chatbots**, **robotics**, **gaming**)?  \\n- What level of experience do you have with Python, ML frameworks, or robotics simulators?\\n\\nAnswering these will help me tailor the next set of resources or projects for you. üöÄ', additional_kwargs={'reasoning_content': 'The user says: \"Hi, I\\'m learning Agentic AI\". They are presumably starting to learn about Agentic AI. They likely want an introduction or resources. We should respond warmly, ask clarifying questions, maybe give an overview, resources, examples. Also we can ask what specific aspects they are interested in: theory, practical implementation, frameworks, ethical considerations. Provide suggestions: reading, courses, books, tutorials. Also mention open-source frameworks like LangChain, Agentic frameworks. Also talk about the difference between agentic AI and general AI. Provide a short guide. Also mention the concept of \"agentic\" meaning agents that act autonomously. Provide some examples: chatbots, autonomous robots, etc. Also mention the key components: perception, reasoning, action, learning, planning. Also mention reinforcement learning, planning, hierarchical RL. Provide references: Sutton & Barto, Russell & Norvig, etc. Also mention research: OpenAI\\'s GPT-4, GPT-3.5, RLHF, etc. Provide open-source libraries: LangChain, Haystack, Agentic, etc. Also mention the concept of \"Agentic AI\" in the context of LLMs: chain-of-thought, self-reflection, multi-agent. Provide a step-by-step learning path: fundamentals, then advanced topics.\\n\\nWe need to keep it friendly. Also mention some resources: Coursera, edX, MIT OpenCourseWare, etc. Provide a few recommended readings: \"Artificial Intelligence: A Modern Approach\" by Russell & Norvig, \"Reinforcement Learning: An Introduction\" by Sutton & Barto, \"Deep Learning\" by Goodfellow. Also mention \"Agentic AI\" in the context of LLMs: \"Agentic AI: The next frontier\" etc. Provide references to research papers: \"Agentic: A Multi-Agent RL for LLMs\" etc.\\n\\nWe can ask user what level they are at. Provide suggestions. Also mention the difference between \"agentic\" vs \"reactive\" AI. Provide examples of agentic AI: self-driving cars, robotic assistants, autonomous drones. Also talk about the architecture: sensors, world model, planning, action.\\n\\nAlso mention the importance of safety and ethics: alignment, value learning, interpretability.\\n\\nAlso mention open-source frameworks: OpenAI\\'s RLHF, RLlib, Ray, etc. Provide resources: RLlib docs, RLlib examples, RLlib\\'s \"Agent\" concept.\\n\\nAlso mention that \"Agentic AI\" is a hot area. Provide references to recent conferences: NeurIPS, ICML, ICLR.\\n\\nAlso ask user about their interests: Are they focusing on LLM-based agents, RL, robotics? Provide tailored suggestions.\\n\\nWe need to keep it concise but helpful.\\n\\nLet\\'s produce a response.'}, response_metadata={'token_usage': {'completion_tokens': 2002, 'prompt_tokens': 78, 'total_tokens': 2080, 'completion_time': 2.064879425, 'prompt_time': 0.003710873, 'queue_time': 0.047085393, 'total_time': 2.068590298}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7eba5217-2296-413e-9ee2-781e6babf67e-0', usage_metadata={'input_tokens': 78, 'output_tokens': 2002, 'total_tokens': 2080})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.invoke({\"messages\": \"Hi, I'm learning Agentic AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a95aa27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Superbot': {'messages': AIMessage(content='Great! LangGraph is a powerful framework for building **graph‚Äëbased language model applications**‚Äîthink of it as a way to stitch together multiple LLM calls, external tools, and custom logic into a cohesive flow that can learn, adapt, and reason over time.\\n\\nBelow is a quick ‚Äústarter kit‚Äù that covers:\\n\\n1. **What LangGraph really is**  \\n2. **Why you‚Äôd want to use it**  \\n3. **Core concepts**  \\n4. **A minimal example**  \\n5. **Where to go from here** (docs, tutorials, community)\\n\\nFeel free to jump to the section that matches your current level of knowledge or ask follow‚Äëup questions.\\n\\n---\\n\\n## 1. What is LangGraph?\\n\\nLangGraph (short for *Language Model Graph*) is a framework built on top of the **LangChain** ecosystem that lets you:\\n\\n| Feature | How it works |\\n|---------|--------------|\\n| **Graph nodes** | Each node represents a unit of computation (e.g., a prompt, a tool call, a data fetch, or a custom function). |\\n| **Edges** | Define the flow between nodes, possibly conditioned on the LLM‚Äôs output. |\\n| **State** | A shared mutable context that flows through the graph, enabling memory, metadata, and back‚Äëtracking. |\\n| **RAG / Retrieval** | Integrate vector stores, knowledge bases, or APIs directly into the graph. |\\n| **Reinforcement** | Use RLHF or other training loops to fine‚Äëtune the graph‚Äôs decision‚Äëmaking. |\\n\\nIn short, LangGraph turns a chain of LLM calls into a **stateful, decision‚Äëmaking graph** that can adapt based on user input or external signals.\\n\\n---\\n\\n## 2. Why Use LangGraph?\\n\\n| Problem | LangGraph Solution |\\n|---------|--------------------|\\n| **Complex multi‚Äëstep reasoning** | Break into nodes; each node does one sub‚Äëtask. |\\n| **Dynamic branching** | Use conditionals or `Switch` nodes that evaluate LLM responses. |\\n| **External tool integration** | Wrap APIs or local functions as nodes (`ToolNode`, `PythonNode`). |\\n| **Persistent memory** | Store state in a database or vector store; the graph can read/write. |\\n| **Training / fine‚Äëtuning** | Graph can be trained end‚Äëto‚Äëend with RLHF or supervised signals. |\\n\\nIf you‚Äôre building a chatbot that needs to browse the web, pull data from a database, or perform calculations, LangGraph gives you a clean, declarative way to describe the workflow.\\n\\n---\\n\\n## 3. Core Concepts\\n\\n| Concept | What it is | Quick example |\\n|---------|------------|---------------|\\n| **Node** | A unit of computation. | `PromptNode`, `PythonNode`, `ToolNode` |\\n| **Edge** | A directed connection. | `node_a -> node_b` |\\n| **State** | Dictionary that carries context. | `state = {\"input\": \"...\", \"history\": []}` |\\n| **Graph** | Collection of nodes & edges. | `GraphBuilder()` |\\n| **Execution** | Running the graph from a start node. | `graph.run(start_node, state)` |\\n| **Conditionals** | Decide next node based on state. | `SwitchNode` or `IfNode` |\\n| **Tools** | External services (e.g., search, DB). | `OpenAIChat`, `RequestsTool` |\\n\\n---\\n\\n## 4. Minimal Example: ‚ÄúQuestion‚ÄëAnswering Bot‚Äù\\n\\nBelow is a **self‚Äëcontained** example that demonstrates:\\n\\n1. Prompting the LLM  \\n2. Calling a simple tool (Python function)  \\n3. Updating state  \\n4. Returning the final answer\\n\\n```python\\n# langgraph_demo.py\\nfrom langgraph.graph import StateGraph, START\\nfrom langgraph.prebuilt import ToolNode\\nfrom langchain.tools import tool\\nfrom langchain_openai import ChatOpenAI\\n\\n# 1. Define a simple Python tool\\n@tool\\ndef add_numbers(a: int, b: int) -> int:\\n    \"\"\"Return the sum of a and b.\"\"\"\\n    return a + b\\n\\n# 2. Build the graph\\ndef build_graph():\\n    graph = StateGraph()\\n\\n    # 2a. Node that asks the LLM for two numbers\\n    def ask_numbers(state):\\n        llm = ChatOpenAI(temperature=0)\\n        prompt = (\\n            \"I want you to give me two integers between 1 and 10, \"\\n            \"separated by a comma. Just give the numbers, no text.\"\\n        )\\n        response = llm.invoke(prompt)\\n        # parse \"3, 7\" -> [3, 7]\\n        numbers = [int(x.strip()) for x in response.content.split(\",\")]\\n        state[\"nums\"] = numbers\\n        return state\\n\\n    # 2b. Node that calls the add_numbers tool\\n    def sum_numbers(state):\\n        a, b = state[\"nums\"]\\n        result = add_numbers(a, b)\\n        state[\"sum\"] = result\\n        return state\\n\\n    # 2c. Node that returns the final answer\\n    def answer(state):\\n        return {\"answer\": f\"The sum of {state[\\'nums\\'][0]} and {state[\\'nums\\'][1]} is {state[\\'sum\\']}.\"}\\n\\n    # 3. Register nodes\\n    graph.add_node(\"ask\", ask_numbers)\\n    graph.add_node(\"sum\", sum_numbers)\\n    graph.add_node(\"answer\", answer)\\n\\n    # 4. Define edges\\n    graph.add_edge(START, \"ask\")\\n    graph.add_edge(\"ask\", \"sum\")\\n    graph.add_edge(\"sum\", \"answer\")\\n\\n    return graph.compile()\\n\\n# 5. Run the graph\\nif __name__ == \"__main__\":\\n    graph = build_graph()\\n    result = graph.invoke({})\\n    print(result[\"answer\"])\\n```\\n\\n**What happens?**\\n\\n1. **`ask_numbers`**: LLM outputs something like `\"3, 7\"`.  \\n2. **`sum_numbers`**: Calls the `add_numbers` tool.  \\n3. **`answer`**: Formats the response.  \\n\\nYou‚Äôll see something like:\\n\\n```\\nThe sum of 3 and 7 is 10.\\n```\\n\\n---\\n\\n## 5. Next Steps & Resources\\n\\n| Resource | What it covers | Link |\\n|----------|----------------|------|\\n| **Official Docs** | Core API, tutorials, examples | https://langgraph.org/docs |\\n| **LangGraph GitHub** | Source, examples, issue tracker | https://github.com/langchain-ai/langgraph |\\n| **LangChain Docs** | Since LangGraph builds on LangChain | https://langchain.com |\\n| **Tutorial: Build a RAG Bot** | Retrieval + LLM | https://langgraph.org/docs/tutorials/rag |\\n| **Tutorial: Multi‚ÄëAgent System** | Agents communicating via graph | https://langgraph.org/docs/tutorials/multi-agent |\\n| **Community Discord** | Ask questions, share projects | https://discord.gg/langchain |\\n| **YouTube Playlist** | Quick demos | Search ‚ÄúLangGraph tutorial‚Äù on YouTube |\\n\\n---\\n\\n## Quick Checklist for Your First Project\\n\\n1. **Define the problem** ‚Äì What does the user want?  \\n2. **List sub‚Äëtasks** ‚Äì Each becomes a node.  \\n3. **Choose tools** ‚Äì External APIs, Python functions, etc.  \\n4. **Sketch the graph** ‚Äì Draw nodes & edges (paper or mind‚Äëmap).  \\n5. **Implement nodes** ‚Äì Simple functions that read/write `state`.  \\n6. **Wire up the graph** ‚Äì `StateGraph` + `add_node` + `add_edge`.  \\n7. **Test locally** ‚Äì Run a few inputs, check state transitions.  \\n8. **Add persistence** ‚Äì If you need memory, plug in a vector store or database.  \\n9. **Iterate** ‚Äì Refine prompts, add error handling, consider RLHF.  \\n\\n---\\n\\n### Got a Specific Use‚ÄëCase?\\n\\n- **Chatbot with browsing**? Use a `BrowserTool` node.  \\n- **Data‚Äëdriven QA**? Add a node that queries a SQL DB.  \\n- **Multi‚Äëagent negotiation**? Use a `SwitchNode` to let agents pick a strategy.\\n\\nJust let me know what you‚Äôre trying to build, and I can sketch a more tailored graph for you!', additional_kwargs={'reasoning_content': 'User says \"I\\'m learning LangGraph\". They likely want help. We need to respond. Should ask what they need. Provide resources, guidance, maybe code example. Let\\'s give overview, resources, example.'}, response_metadata={'token_usage': {'completion_tokens': 1795, 'prompt_tokens': 75, 'total_tokens': 1870, 'completion_time': 1.8329083800000001, 'prompt_time': 0.003541826, 'queue_time': 0.047679183, 'total_time': 1.8364502059999999}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5966fbb1-12e6-4bcf-a6fb-4959036955b0-0', usage_metadata={'input_tokens': 75, 'output_tokens': 1795, 'total_tokens': 1870})}}\n"
     ]
    }
   ],
   "source": [
    "for event in graph_builder.stream({\"messages\": \"I'm learning LangGraph\"}):\n",
    "    print(event)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
